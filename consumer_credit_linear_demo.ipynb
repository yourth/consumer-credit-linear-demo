{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Credit Linear Demo for ModelOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.1.5\n",
      "numpy: 1.19.5\n",
      "sklearn: 0.24.2\n",
      "scipy: 1.5.4\n",
      "pickle: 4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"pandas:\", pd.__version__)\n",
    "\n",
    "import numpy as np\n",
    "print(\"numpy:\", np.__version__)\n",
    "\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(\"sklearn:\", skl.__version__)\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.special import logit\n",
    "from scipy.stats import binom_test\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.special import logit\n",
    "print(\"scipy:\", sp.__version__)\n",
    "\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "\n",
    "import pickle\n",
    "print(\"pickle:\", pickle.format_version)\n",
    "\n",
    "import shap\n",
    "print(\"shap:\", shap.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modelop.init\n",
    "def begin():\n",
    "    global explainer, lr_model, threshold, features, rent_ratio, gamma_args, \\\n",
    "            logit_int_rate_mean\n",
    "    model_artifacts = pickle.load(open(\"model_artifacts.pkl\", \"rb\"))\n",
    "    explainer = model_artifacts['explainer']\n",
    "    lr_model = model_artifacts['lr_model']\n",
    "    threshold = model_artifacts['threshold']\n",
    "    features = model_artifacts['features']\n",
    "    rent_ratio = model_artifacts['rent_ratio']\n",
    "    gamma_args = model_artifacts['gamma_args']\n",
    "    logit_int_rate_mean = model_artifacts['logit_int_rate_mean']\n",
    "    pass\n",
    "\n",
    "\n",
    "#modelop.score\n",
    "def action(datum):\n",
    "    datum = pd.DataFrame(datum, index=[0])\n",
    "    prep_datum = preprocess(datum)\n",
    "    datum = pd.concat([datum, prep_datum], axis=1)\n",
    "    datum['probability'] = prediction(datum)\n",
    "    datum['prediction'] = datum.probability \\\n",
    "                          .apply(lambda x: x > threshold).astype(int)\n",
    "    yield datum.loc[:, ['id', 'probability', 'prediction']] \\\n",
    "            .to_dict(orient='records')[0]\n",
    "\n",
    "        \n",
    "def preprocess(data):\n",
    "    prep_data = pd.DataFrame(index=data.index)\n",
    "    prep_data[\"logit_int_rate\"] = data.int_rate.apply(logit)\n",
    "    prep_data[\"log_annual_inc\"] = data.annual_inc.apply(np.log)\n",
    "    prep_data[\"log_credit_age\"] = data.credit_age.apply(np.log)\n",
    "    prep_data[\"log_loan_amnt\"] = data.loan_amnt.apply(np.log)\n",
    "    prep_data[\"rent_indicator\"] = data.home_ownership.isin(['RENT']).astype(int)\n",
    "    return prep_data\n",
    "\n",
    "\n",
    "def prediction(data):\n",
    "    return lr_model.predict_proba(data.loc[:, features])[:,1]\n",
    "\n",
    "\n",
    "#modelop.metrics\n",
    "def metrics(data):\n",
    "    metrics = {}\n",
    "    prep_data = preprocess(data)\n",
    "    data = pd.concat([data, prep_data], axis=1)\n",
    "    data.loc[:, 'probabilities'] = prediction(data)\n",
    "    data.loc[:, 'predictions'] = data.probabilities \\\n",
    "                                     .apply(lambda x: threshold > x) \\\n",
    "                                     .astype(int)\n",
    "    \n",
    "    if is_validated(data):\n",
    "       f1 = f1_score(data.loan_status, data.predictions)\n",
    "       cm = confusion_matrix(data.loan_status, data.predictions)\n",
    "       labels = ['Fully Paid', 'Charged Off']\n",
    "       cm = matrix_to_dicts(cm, labels)\n",
    "       fpr, tpr, thres = roc_curve(data.loan_status, data.probabilities)\n",
    "       auc_val = roc_auc_score(data.loan_status, data.probabilities)\n",
    "       rc = [{'fpr': x[0], 'tpr': x[1]} for x in list(zip(fpr, tpr))]\n",
    "       metrics['f1_score'] = f1\n",
    "       metrics['confusion_matrix'] = cm\n",
    "       metrics['auc'] = auc_val\n",
    "       metrics['ROC'] = rc\n",
    "       metrics['bias'] = get_bias_metrics(data)\n",
    "\n",
    "    metrics['drift_metrics'] = get_drift_metrics(data)\n",
    "    metrics['shap'] = get_shap_values(data)\n",
    "    yield metrics\n",
    "\n",
    "    \n",
    "def is_validated(data):\n",
    "    return ('loan_status' in data.columns)\n",
    "\n",
    "\n",
    "def get_bias_metrics(data):\n",
    "    bias = Bias()\n",
    "    group = Group()\n",
    "    old_columns = ['predictions', 'loan_status', 'forty_plus_indicator']\n",
    "    new_columns = ['score', 'label_value', 'forty_plus_indicator']\n",
    "    scored_data = data.loc[:, old_columns]\n",
    "    renamer = dict(zip(scored_data.columns, new_columns))\n",
    "    scored_data = scored_data.rename(columns = renamer)\n",
    "\n",
    "    data_processed, _ = preprocess_input_df(scored_data)\n",
    "    xtab, _ = group.get_crosstabs(data_processed)\n",
    "    attribute_columns = ['attribute_name', 'attribute_value']\n",
    "    absolute_metrics = group.list_absolute_metrics(xtab)\n",
    "    absolute_metrics_df = xtab[attribute_columns + absolute_metrics].round(2)\n",
    "    bias_df = bias.get_disparity_predefined_groups(\n",
    "        xtab,\n",
    "        original_df=data_processed,\n",
    "        ref_groups_dict={'forty_plus_indicator': 'Under Forty'},\n",
    "        alpha=0.05, mask_significance=True\n",
    "    )\n",
    "    calculated_disparities = bias.list_disparities(bias_df)\n",
    "    disparity_metrics_df = bias_df[attribute_columns + calculated_disparities]\n",
    "    abs_metrics = absolute_metrics_df.where(pd.notnull(absolute_metrics_df),\n",
    "                                            None).to_dict(orient='records')\n",
    "    disp_metrics = disparity_metrics_df.where(pd.notnull(disparity_metrics_df),\n",
    "                                            None).to_dict(orient='records')\n",
    "    return dict(absolute_metrics = abs_metrics,\n",
    "                disparity_metrics = disp_metrics)\n",
    "\n",
    "\n",
    "def get_shap_values(data):\n",
    "    shap_values = explainer.shap_values(data.loc[:, features])\n",
    "    shap_values = np.mean(abs(shap_values), axis=0).tolist()\n",
    "    shap_values = dict(zip(features, shap_values))\n",
    "    sorted_shap_values = {k: v for k, v in sorted(shap_values.items(),\n",
    "                                                  key=lambda x: x[1])}\n",
    "    return sorted_shap_values\n",
    "\n",
    "\n",
    "def get_drift_metrics(data):\n",
    "    num_of_renters = data.rent_indicator.sum()\n",
    "    size_of_sample = data.shape[0]\n",
    "    rent_feat_binom_pvalue = binom_test(x=num_of_renters, \n",
    "                                        n=size_of_sample, \n",
    "                                        p=rent_ratio)\n",
    "\n",
    "    logit_int_rate_pvalue = ttest_1samp(a=data.logit_int_rate,\n",
    "                                        popmean=logit_int_rate_mean)[1]\n",
    "    pred_log_probs = lr_model.predict_log_proba(X=data.loc[:, features])[:, 1]\n",
    "    neg_log_probs = -1*pred_log_probs\n",
    "    output_logprob_pvalue = kstest(neg_log_probs, \n",
    "                                   'gamma', \n",
    "                                   args=gamma_args)[1]\n",
    "    drift_metrics = dict(renters_binom_pvalue=rent_feat_binom_pvalue,\n",
    "                         output_logprob_pvalue=output_logprob_pvalue,\n",
    "                        logit_int_rate_ttest_pvalue=logit_int_rate_pvalue)\n",
    "                \n",
    "    return drift_metrics\n",
    "\n",
    "\n",
    "def matrix_to_dicts(matrix, labels):\n",
    "    cm = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        cm.append(dict(zip(labels, matrix[idx, :].tolist())))\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
